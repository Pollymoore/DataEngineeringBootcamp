{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkRDDs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4Fhk/bAbIWfk2RmYoA7Ui",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pollymoore/DataEngineeringBootcamp/blob/main/SparkRDDs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGPq1fxfxsd0",
        "outputId": "fe645582-df8b-4e18-cae4-26ae9226583f"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 68 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 48.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=8f7052a92247e0e9ee1071c22ec839873cd7df399beb1f7b061b8e2bf3aebcd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "d7ZZIl1RyWvy",
        "outputId": "a9de772d-b59d-41b0-9c42-eef4dc76e363"
      },
      "source": [
        "#import modules\n",
        "from pyspark import SparkContext\n",
        "sc =SparkContext()\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-de9bd63d3f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    345\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 347\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-eb864ff61741>:2 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnvXbzOidbFd"
      },
      "source": [
        "#Creating my RDD- we're creating a list and making this parallelised, using the parallelize method - otherwise this would simply be a list\n",
        "myRDD = sc.parallelize ([('Polly', 'Data Engineering'), ('Roger', 'Modelling'), ('Tom', 'Data Science'), ('Sam' 'API')])"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXYsdSy3ocYZ",
        "outputId": "90ffd17a-7588-4136-fba8-a5e80996ec16"
      },
      "source": [
        "#Count the number of items in the RDD\n",
        "myRDD.count()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VQCkmmVgaiT",
        "outputId": "0c455601-6e0b-42ff-f65d-f77435766e50"
      },
      "source": [
        "#Read a set number of number of items in the RDD\n",
        "myRDD.take(3)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Polly', 'Data Engineering'),\n",
              " ('Roger', 'Modelling'),\n",
              " ('Tom', 'Data Science')]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm6wuBd5gBfk"
      },
      "source": [
        "#Can also load data from external sources\n",
        "myRDDtxtFile = sc.textFile('ManicStreetPreachersLyrics.txt')"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgDHge8FijGQ",
        "outputId": "74a1e050-3942-46b7-81cd-1d06230861b2"
      },
      "source": [
        "#Count the number of items in the RDD text file\n",
        "myRDDtxtFile.count()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14614"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAns9hV8ixgn",
        "outputId": "6922eeaf-d02f-4b95-de65-2881f3a3cc8f"
      },
      "source": [
        "#Read a set number of number of items in the RDD\n",
        "myRDDtxtFile.take(3)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"New Art Riot\"', '', 'Vintage aromas and vintage ideals']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DLf5P0DjCtM",
        "outputId": "5918f4fb-0cb2-4498-af47-c120ea6694d6"
      },
      "source": [
        "#Filter an RDD\n",
        "Polly = myRDD.filter(lambda x: 'Polly'  in x)\n",
        "PollyFiltered = Polly.collect()\n",
        "print(PollyFiltered)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Roger', 'Modelling'), ('Tom', 'Data Science'), 'SamAPI']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDcvzE8bi1g9"
      },
      "source": [
        "##transformation - going to split our RDD. Need to create a function:\n",
        "\n",
        "def Func (para):\n",
        "    para = para.split()\n",
        "    return para\n",
        "NewRDD=myRDDtxtFile.map(Func)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH3EFHsejKZ-",
        "outputId": "796b9e8c-9717-4347-9a27-9a9e5869a694"
      },
      "source": [
        "NewRDD.take(10)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['\"Motorcycle', 'Emptiness\"'],\n",
              " [],\n",
              " ['Culture', 'sucks', 'down', 'words'],\n",
              " ['Itemise', 'loathing', 'and', 'feed', 'yourself', 'smiles'],\n",
              " ['Organise', 'your', 'safe', 'tribal', 'war'],\n",
              " ['Hurt', 'maim', 'kill', 'and', 'enslave', 'the', 'ghetto'],\n",
              " [],\n",
              " ['Each', 'day', 'living', 'out', 'a', 'lie'],\n",
              " ['Life', 'sold', 'cheaply', 'forever,', 'ever,', 'ever'],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39o74uZLrn54"
      },
      "source": [
        "#Transform dataset into a new RDD so we can see each word in a list\n",
        "RDDFlat= myRDDtxtFile.flatMap(Func)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRhUFwU-r6YJ",
        "outputId": "09b4df3d-3e52-41c5-d33b-5ae1e819c391"
      },
      "source": [
        "RDDFlat.take(100)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"Motorcycle',\n",
              " 'Emptiness\"',\n",
              " 'Culture',\n",
              " 'sucks',\n",
              " 'down',\n",
              " 'words',\n",
              " 'Itemise',\n",
              " 'loathing',\n",
              " 'and',\n",
              " 'feed',\n",
              " 'yourself',\n",
              " 'smiles',\n",
              " 'Organise',\n",
              " 'your',\n",
              " 'safe',\n",
              " 'tribal',\n",
              " 'war',\n",
              " 'Hurt',\n",
              " 'maim',\n",
              " 'kill',\n",
              " 'and',\n",
              " 'enslave',\n",
              " 'the',\n",
              " 'ghetto',\n",
              " 'Each',\n",
              " 'day',\n",
              " 'living',\n",
              " 'out',\n",
              " 'a',\n",
              " 'lie',\n",
              " 'Life',\n",
              " 'sold',\n",
              " 'cheaply',\n",
              " 'forever,',\n",
              " 'ever,',\n",
              " 'ever',\n",
              " 'Under',\n",
              " 'neon',\n",
              " 'loneliness',\n",
              " 'motorcycle',\n",
              " 'emptiness',\n",
              " 'Under',\n",
              " 'neon',\n",
              " 'loneliness',\n",
              " 'motorcycle',\n",
              " 'emptiness',\n",
              " 'Life',\n",
              " 'lies',\n",
              " 'a',\n",
              " 'slow',\n",
              " 'suicide',\n",
              " 'Orthodox',\n",
              " 'dreams',\n",
              " 'and',\n",
              " 'symbolic',\n",
              " 'myths',\n",
              " 'From',\n",
              " 'feudal',\n",
              " 'serf',\n",
              " 'to',\n",
              " 'spender',\n",
              " 'This',\n",
              " 'wonderful',\n",
              " 'world',\n",
              " 'of',\n",
              " 'purchase',\n",
              " 'power',\n",
              " 'Just',\n",
              " 'like',\n",
              " 'lungs',\n",
              " 'sucking',\n",
              " 'on',\n",
              " 'air',\n",
              " 'Survivals',\n",
              " 'natural',\n",
              " 'as',\n",
              " 'sorrow,',\n",
              " 'sorrow,',\n",
              " 'sorrow',\n",
              " 'Under',\n",
              " 'neon',\n",
              " 'loneliness',\n",
              " 'motorcycle',\n",
              " 'emptiness',\n",
              " 'Under',\n",
              " 'neon',\n",
              " 'loneliness',\n",
              " 'motorcycle',\n",
              " 'emptiness',\n",
              " 'All',\n",
              " 'we',\n",
              " 'want',\n",
              " 'from',\n",
              " 'you',\n",
              " 'are',\n",
              " 'the',\n",
              " 'kicks',\n",
              " \"you've\",\n",
              " 'given',\n",
              " 'us']"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfnyyIeAh7eY"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}